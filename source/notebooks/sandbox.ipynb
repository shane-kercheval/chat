{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/code\n"
     ]
    }
   ],
   "source": [
    "%cd /code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "openai_token = os.getenv('OPENAI_TOKEN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 33\n",
      "\tPrompt Tokens: 26\n",
      "\tCompletion Tokens: 7\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $6.6e-05\n",
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "model_name = 'gpt-3.5-turbo'\n",
    "llm = ChatOpenAI(\n",
    "    model=model_name,\n",
    "    temperature=0,\n",
    "    max_tokens=1000,\n",
    "    openai_api_key=openai_token,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"What is the capital of France?\"),\n",
    "]\n",
    "\n",
    "with get_openai_callback() as callback:\n",
    "    response = llm(messages)\n",
    "\n",
    "print(callback)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "7\n",
      "33\n",
      "1\n",
      "0.000066\n"
     ]
    }
   ],
   "source": [
    "print(f\"{callback.prompt_tokens:,}\")\n",
    "print(f\"{callback.completion_tokens:,}\")\n",
    "print(f\"{callback.total_tokens:,}\")\n",
    "print(f\"{callback.successful_requests:,}\")\n",
    "print(f\"{callback.total_cost:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}),\n",
       " HumanMessage(content='What is the capital of France?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='The capital of France is Paris.', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='What is the lat/long?', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages += [response]\n",
    "messages += [HumanMessage(content=\"What is the lat/long?\")]\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 75\n",
      "\tPrompt Tokens: 50\n",
      "\tCompletion Tokens: 25\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00015000000000000001\n",
      "The latitude and longitude of Paris, France is 48.8566° N, 2.3522° E.\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as callback:\n",
    "    response = llm(messages)\n",
    "\n",
    "print(callback)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"content\": \"The latitude and longitude of Paris, France is 48.8566\\\\u00b0 N, 2.3522\\\\u00b0 E.\", \"additional_kwargs\": {}, \"example\": false}'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "from langchain.callbacks.openai_info import OpenAICallbackHandler\n",
    "openai_callback = OpenAICallbackHandler()\n",
    "\n",
    "model_name = 'gpt-3.5-turbo'\n",
    "llm = ChatOpenAI(\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler(), openai_callback],\n",
    "    model=model_name,\n",
    "    temperature=0,\n",
    "    max_tokens=1000,\n",
    "    openai_api_key=openai_token,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"What is the capital of France?\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris."
     ]
    }
   ],
   "source": [
    "# https://github.com/hwchase17/langchain/issues/3114\n",
    "with get_openai_callback() as callback_no_info:\n",
    "    response = llm(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokens Used: 0\n",
       "\tPrompt Tokens: 0\n",
       "\tCompletion Tokens: 0\n",
       "Successful Requests: 0\n",
       "Total Cost (USD): $0.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_no_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokens Used: 0\n",
       "\tPrompt Tokens: 0\n",
       "\tCompletion Tokens: 0\n",
       "Successful Requests: 1\n",
       "Total Cost (USD): $0.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 0\n",
      "\tPrompt Tokens: 0\n",
      "\tCompletion Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0\n",
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "print(callback)\n",
    "print(response.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to implement streaming in streamlit https://github.com/hwchase17/chat-langchain/issues/39"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to implement Async callback\n",
    "\n",
    "https://github.com/hwchase17/langchain/issues/4583"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using streaming with FastAPI\n",
    "\n",
    "- https://github.com/hwchase17/langchain/discussions/1706\n",
    "- https://stackoverflow.com/questions/76357732/stream-a-langchain-openai-response-with-fastapi\n",
    "- https://gist.github.com/ninely/88485b2e265d852d3feb8bd115065b1a?permalink_comment_id=4537719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://127.0.0.1:8000/stream'\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "data = {'message': 'hello!'}\n",
    "\n",
    "response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "print(response.status_code)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data: \\n\\ndata: Hello\\n\\ndata:  there\\n\\ndata: !\\n\\ndata:  How\\n\\ndata:  can\\n\\ndata:  I\\n\\ndata:  assist\\n\\ndata:  you\\n\\ndata:  today\\n\\ndata: ?\\n\\ndata: \\n\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft whispers in the breeze,\n",
      "Leaves rustling with ease,\n",
      "Birds chirping in the trees,\n",
      "Nature's symphony, oh please!\n",
      "\n",
      "The sun sets in the west,\n",
      "Painting the sky with its best,\n",
      "Colors of orange, red and gold,\n",
      "A sight that never gets old.\n",
      "\n",
      "Stars twinkle in the night,\n",
      "A moon that shines so bright,\n",
      "Peaceful and calm, oh what a delight,\n",
      "This moment, oh so right.\n",
      "\n",
      "Nature's beauty, a gift so pure,\n",
      "A treasure that will forever endure,\n",
      "Let's cherish and protect it for sure,\n",
      "For generations to come, let it endure."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://127.0.0.1:8000/stream'\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "data = {'message': 'Write a small poem no longer than 15 words.'}\n",
    "\n",
    "response = requests.post(url, json=data, headers=headers, stream=True)\n",
    "\n",
    "for chunk in response.iter_content(chunk_size=128):\n",
    "    print(chunk.decode('utf-8'), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sunrise hues paint the sky,\n",
      "New day dawns, hope awakens high."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://127.0.0.1:8000/stream'\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "data = {'message': 'Write a small poem no longer than 15 words.'}\n",
    "\n",
    "response = requests.post(url, json=data, headers=headers, stream=True)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Extract the additional information from the response headers\n",
    "    total_characters = response.headers.get(\"total_characters\")\n",
    "\n",
    "    # Process the streamed data\n",
    "    for chunk in response.iter_content(chunk_size=1024):\n",
    "        if chunk:\n",
    "            # Process the streamed data here\n",
    "            print(chunk.decode(), end='')\n",
    "\n",
    "    # Use the extracted additional information\n",
    "    if total_characters:\n",
    "        print()\n",
    "        print(\"Additional Information:\", total_characters)\n",
    "else:\n",
    "    print(\"Error:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': 'Mon, 05 Jun 2023 21:53:09 GMT', 'server': 'uvicorn', 'content-type': 'text/event-stream; charset=utf-8', 'Transfer-Encoding': 'chunked'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.headers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DuckDuckGo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'About - OpenAI',\n",
       "  'href': 'https://openai.com/about/',\n",
       "  'body': 'About OpenAI is an AI research and deployment company. Our mission is to ensure that artificial general intelligence benefits all of humanity. Our vision for the future of AGI Our mission is to ensure that artificial general intelligence—AI systems that are generally smarter than humans—benefits all of humanity. Read our plan for AGI'},\n",
       " {'title': 'OpenAI - Wikipedia',\n",
       "  'href': 'https://en.wikipedia.org/wiki/OpenAI',\n",
       "  'body': 'OpenAI is an American artificial intelligence (AI) research laboratory consisting of the non-profit OpenAI Incorporated and its for-profit subsidiary corporation OpenAI Limited Partnership.OpenAI conducts AI research with the declared intention of promoting and developing a friendly AI.. OpenAI was founded in 2015 by Ilya Sutskever, Greg Brockman, Trevor Blackwell, Vicki Cheung, Andrej ...'},\n",
       " {'title': 'What is OpenAI? Definition and History from TechTarget',\n",
       "  'href': 'https://www.techtarget.com/searchenterpriseai/definition/OpenAI',\n",
       "  'body': \"OpenAI. OpenAI is a private research laboratory that aims to develop and direct artificial intelligence ( AI) in ways that benefit humanity as a whole. The company was founded by Elon Musk, Sam Altman and others in 2015 and is headquartered in San Francisco. OpenAI was created in part because of its founders' existential concerns about the ...\"},\n",
       " {'title': 'What is Azure OpenAI Service? - Azure Cognitive Services',\n",
       "  'href': 'https://learn.microsoft.com/en-us/azure/cognitive-services/openai/overview',\n",
       "  'body': \"05/16/2023 8 contributors Feedback In this article Responsible AI How do I get access to Azure OpenAI? Comparing Azure OpenAI and OpenAI Key concepts Next steps Azure OpenAI Service provides REST API access to OpenAI's powerful language models including the GPT-3, Codex and Embeddings model series.\"},\n",
       " {'title': 'Introducing ChatGPT - OpenAI',\n",
       "  'href': 'https://openai.com/blog/chatgpt',\n",
       "  'body': \"OpenAI Product, Announcements ChatGPT is a sibling model to InstructGPT, which is trained to follow an instruction in a prompt and provide a detailed response. We are excited to introduce ChatGPT to get users' feedback and learn about its strengths and weaknesses. During the research preview, usage of ChatGPT is free. Try it now at chat.openai.com.\"}]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "from duckduckgo_search import DDGS\n",
    "ddgs = DDGS()\n",
    "keywords = 'what is openai?'\n",
    "ddgs_text_gen = ddgs.text(keywords, region='wt-wt', safesearch='Off', timelimit='y')\n",
    "first_n_items = list(itertools.islice(ddgs_text_gen, 0, 5))\n",
    "first_n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/duckduckgo_search/compat.py:20: UserWarning: ddg is deprecated. Use DDGS().text() generator\n",
      "  warnings.warn(\"ddg is deprecated. Use DDGS().text() generator\")\n",
      "/usr/local/lib/python3.11/site-packages/duckduckgo_search/compat.py:22: UserWarning: parameter time is deprecated, use parameter timelimit\n",
      "  warnings.warn(\"parameter time is deprecated, use parameter timelimit\")\n",
      "/usr/local/lib/python3.11/site-packages/duckduckgo_search/compat.py:24: UserWarning: parameter page is deprecated, use DDGS().text() generator\n",
      "  warnings.warn(\"parameter page is deprecated, use DDGS().text() generator\")\n",
      "/usr/local/lib/python3.11/site-packages/duckduckgo_search/compat.py:26: UserWarning: parameter max_results is deprecated, use DDGS().text()\n",
      "  warnings.warn(\"parameter max_results is deprecated, use DDGS().text()\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About - OpenAI\n",
      "https://openai.com/about/\n",
      "About OpenAI is an AI research and deployment company. Our mission is to ensure that artificial general intelligence benefits all of humanity. Our vision for the future of AGI Our mission is to ensure that artificial general intelligence—AI systems that are generally smarter than humans—benefits all of humanity. Read our plan for AGI\n",
      "---\n",
      "OpenAI - Wikipedia\n",
      "https://en.wikipedia.org/wiki/OpenAI\n",
      "OpenAI is an American artificial intelligence (AI) research laboratory consisting of the non-profit OpenAI Incorporated and its for-profit subsidiary corporation OpenAI Limited Partnership.OpenAI conducts AI research with the declared intention of promoting and developing friendly AI.. OpenAI was founded in 2015 by Ilya Sutskever, Greg Brockman, Trevor Blackwell, Vicki Cheung, Andrej Karpathy ...\n",
      "---\n",
      "What is OpenAI? Definition and History from TechTarget\n",
      "https://www.techtarget.com/searchenterpriseai/definition/OpenAI\n",
      "OpenAI. OpenAI is a private research laboratory that aims to develop and direct artificial intelligence ( AI) in ways that benefit humanity as a whole. The company was founded by Elon Musk, Sam Altman and others in 2015 and is headquartered in San Francisco. OpenAI was created in part because of its founders' existential concerns about the ...\n",
      "---\n",
      "Introducing ChatGPT - OpenAI\n",
      "https://openai.com/blog/chatgpt\n",
      "OpenAI Product, Announcements ChatGPT is a sibling model to InstructGPT, which is trained to follow an instruction in a prompt and provide a detailed response. We are excited to introduce ChatGPT to get users' feedback and learn about its strengths and weaknesses. During the research preview, usage of ChatGPT is free. Try it now at chat.openai.com.\n",
      "---\n",
      "What is Azure OpenAI Service? - Azure Cognitive Services\n",
      "https://learn.microsoft.com/en-us/azure/cognitive-services/openai/overview\n",
      "Article 05/16/2023 8 contributors Feedback In this article Responsible AI How do I get access to Azure OpenAI? Comparing Azure OpenAI and OpenAI Key concepts Next steps Azure OpenAI Service provides REST API access to OpenAI's powerful language models including the GPT-3, Codex and Embeddings model series.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from langchain.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "wrapper = DuckDuckGoSearchAPIWrapper()\n",
    "results = wrapper.results('what is openai?', 5)\n",
    "\n",
    "for result in results:\n",
    "    print(result[\"title\"])\n",
    "    print(result[\"link\"])\n",
    "    print(result[\"snippet\"])\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversational Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.pinecone.io/learn/langchain-conversational-memory/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'adsf', 'more_context': 'afdafddafdsafsd'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = {'context': 'adsf', 'more_context': 'afdafddafdsafsd'}\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context adsf\n",
      "more_context afdafddafdsafsd\n"
     ]
    }
   ],
   "source": [
    "for k, v in temp.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n        This is a prompt.\\n\\n        It has fields like this {{context}}\\n\\n        And this:\\n\\n        ```\\n        {{more_context}}\\n        ```\\n        '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_gpt_message = \"\"\"\n",
    "        This is a prompt.\n",
    "\n",
    "        It has fields like this {{context}}\n",
    "\n",
    "        And this:\n",
    "\n",
    "        ```\n",
    "        {{more_context}}\n",
    "        ```\n",
    "        \"\"\"\n",
    "chat_gpt_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n        This is a prompt.\\n\\n        It has fields like this adsf\\n\\n        And this:\\n\\n        ```\\n        afdafddafdsafsd\\n        ```\\n        '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key, value in temp.items():\n",
    "    chat_gpt_message = chat_gpt_message.replace(\"{{\" + key + \"}}\", value)\n",
    "\n",
    "chat_gpt_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None or ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
      "9\n",
      "8 7\n",
      "6 5\n",
      "4 3\n",
      "2 1\n"
     ]
    }
   ],
   "source": [
    "my_list = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "#my_list = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "# my_list = [1]\n",
    "my_list = list(reversed(my_list))\n",
    "print(my_list)\n",
    "print(len(my_list))\n",
    "for i in range(0, len(my_list) - 1, 2):\n",
    "    item1 = my_list[i]\n",
    "    item2 = my_list[i + 1]\n",
    "    \n",
    "    # Do something with item1 and item2\n",
    "    print(item1, item2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'asdf' in set(['sdfdsdf', 'ddd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comment-code.yml',\n",
       " 'make-text-sound-better.yml',\n",
       " 'write-unit-tests.yml',\n",
       " 'python-doc-strings.yml',\n",
       " 'improve-code.yml',\n",
       " 'summarize-text.yml',\n",
       " 'explain-code.yml',\n",
       " 'find-issues-in-code.yml']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "template_files = os.listdir('/code/prompt_templates/')\n",
    "template_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Comment code': {'category': 'code',\n",
       "  'template': 'Create helpful comments throughout the following code:\\n\\n```\\n{{code}}\\n```\\n'},\n",
       " 'Make text sound better': {'category': 'text',\n",
       "  'template': 'Improve the text below. Make it sound clear and concise. It should sound professional while remaining informal.\\n\\n```\\n{{text}}\\n```\\n'},\n",
       " 'Write tests for code': {'category': 'code',\n",
       "  'template': 'Write unit tests using pytest for the following code. Try to test for both edge cases and standard cases.\\n\\n```\\n{{code}}\\n```\\n'},\n",
       " 'Create doc strings': {'category': 'code',\n",
       "  'template': 'Create doc strings and type hints for the following python function. It should be in the format:\\n\\n```\\ndef func(variable_a: str) -> int:\\n    \"\"\"\\n    <This is the description>\\n\\n    Args:\\n        variable_a: <description of variable_a>  \\n    \"\"\"\\n    return 1\\n```\\n\\nHere is the function:\\n\\n```\\n{{python_function}}\\n```\\n'},\n",
       " 'Improve and optimize code': {'category': 'code',\n",
       "  'template': 'Improve and optimize the following code. Explain the the improvements made.\\n\\n```\\n{{code}}\\n```\\n'},\n",
       " 'Summarize text': {'category': 'text',\n",
       "  'template': 'Summarize the following text and explain any advanced concepts.\\n\\n```\\n{{text}}\\n```\\n'},\n",
       " 'Explain code': {'category': 'code',\n",
       "  'template': 'Explain the following code:\\n\\n```\\n{{code}}\\n```\\n'},\n",
       " 'Find issues in code': {'category': 'code',\n",
       "  'template': 'Find issues in the following code:\\n\\n```\\n{{code}}\\n```\\n'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "templates = {}\n",
    "import yaml\n",
    "for file_name in template_files:\n",
    "    with open(os.path.join('/code/prompt_templates/', file_name)) as handle:\n",
    "        yaml_data = yaml.safe_load(handle)\n",
    "        template_name = yaml_data.pop('name')\n",
    "        assert template_name not in templates\n",
    "        templates[template_name] = yaml_data\n",
    "templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Improve the text below. Make it sound clear and concise. It should sound professional while remaining informal.\n",
      "\n",
      "```\n",
      "{{text}}\n",
      "```\n",
      "`\n"
     ]
    }
   ],
   "source": [
    "print('`' + templates[\"Make text sound better\"]['template'] + '`')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Comment code',\n",
       " 'Make text sound better',\n",
       " 'Write tests for code',\n",
       " 'Create doc strings',\n",
       " 'Improve and optimize code',\n",
       " 'Summarize text',\n",
       " 'Explain code',\n",
       " 'Find issues in code']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(templates.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'code'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "templates['Comment code']['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Create doc strings',\n",
       "  {'category': 'code',\n",
       "   'template': 'Create doc strings and type hints for the following python function. It should be in the format:\\n\\n```\\ndef func(variable_a: str) -> int:\\n    \"\"\"\\n    <This is the description>\\n\\n    Args:\\n        variable_a: <description of variable_a>  \\n    \"\"\"\\n    return 1\\n```\\n\\nHere is the function:\\n\\n```\\n{{python_function}}\\n```\\n'}),\n",
       " ('Comment code',\n",
       "  {'category': 'code',\n",
       "   'template': 'Create helpful comments throughout the following code:\\n\\n```\\n{{code}}\\n```\\n'}),\n",
       " ('Explain code',\n",
       "  {'category': 'code',\n",
       "   'template': 'Explain the following code:\\n\\n```\\n{{code}}\\n```\\n'}),\n",
       " ('Find issues in code',\n",
       "  {'category': 'code',\n",
       "   'template': 'Find issues in the following code:\\n\\n```\\n{{code}}\\n```\\n'}),\n",
       " ('Improve and optimize code',\n",
       "  {'category': 'code',\n",
       "   'template': 'Improve and optimize the following code. Explain the the improvements made.\\n\\n```\\n{{code}}\\n```\\n'}),\n",
       " ('Write tests for code',\n",
       "  {'category': 'code',\n",
       "   'template': 'Write unit tests using pytest for the following code. Try to test for both edge cases and standard cases.\\n\\n```\\n{{code}}\\n```\\n'}),\n",
       " ('Make text sound better',\n",
       "  {'category': 'text',\n",
       "   'template': 'Improve the text below. Make it sound clear and concise. It should sound professional while remaining informal.\\n\\n```\\n{{text}}\\n```\\n'}),\n",
       " ('Summarize text',\n",
       "  {'category': 'text',\n",
       "   'template': 'Summarize the following text and explain any advanced concepts.\\n\\n```\\n{{text}}\\n```\\n'})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_dict = sorted(templates.items(), key=lambda x: (x[1]['category'], x[1]['template']))\n",
    "sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
